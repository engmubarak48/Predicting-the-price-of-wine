{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175000, 13)\n",
      "(83210, 14)\n",
      "(83210, 2)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('ammi-bootcamp-kaggle-competition/train.csv', index_col='id')\n",
    "test = pd.read_csv('ammi-bootcamp-kaggle-competition/test.csv', index_col='id')\n",
    "submission = pd.read_csv('ammi-bootcamp-kaggle-competition/Sample_Submission.csv')\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate missing values by column\n",
    "def missing_values_table(df):\n",
    "        # Total missing values\n",
    "        mis_val = df.isnull().sum()\n",
    "        \n",
    "        # Percentage of missing values\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "        \n",
    "        # Make a table with the results\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        \n",
    "        # Rename the columns\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        \n",
    "        # Sort the table by percentage of missing descending\n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "        \n",
    "        # Print some summary information\n",
    "        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
    "            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "              \" columns that have missing values.\")\n",
    "        \n",
    "        # Return the dataframe with missing information\n",
    "        return mis_val_table_ren_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175000,)\n"
     ]
    }
   ],
   "source": [
    "labels = train['price']\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175000, 10)\n",
      "(83210, 10)\n"
     ]
    }
   ],
   "source": [
    "train = train.drop(columns = ['taster_twitter_handle', 'taster_name', 'price'])\n",
    "test = test.drop(columns = ['index','taster_twitter_handle','taster_name', 'price'])\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your selected dataframe has 10 columns.\n",
      "There are 7 columns that have missing values.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>% of Total Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>region_2</td>\n",
       "      <td>99606</td>\n",
       "      <td>56.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>title</td>\n",
       "      <td>92811</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>designation</td>\n",
       "      <td>52266</td>\n",
       "      <td>29.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>region_1</td>\n",
       "      <td>28534</td>\n",
       "      <td>16.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>country</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>province</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>variety</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Missing Values  % of Total Values\n",
       "region_2              99606               56.9\n",
       "title                 92811               53.0\n",
       "designation           52266               29.9\n",
       "region_1              28534               16.3\n",
       "country                  47                0.0\n",
       "province                 47                0.0\n",
       "variety                   1                0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values_table(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175000, 8)\n",
      "(83210, 8)\n"
     ]
    }
   ],
   "source": [
    "train = train.drop(columns = ['region_2', 'title'])\n",
    "test = test.drop(columns = ['region_2', 'title'])\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32027</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>This is a fine rich balanced wine. It has ripe...</td>\n",
       "      <td>Vila Santa Reserva</td>\n",
       "      <td>88.870874</td>\n",
       "      <td>Alentejano</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PORTUGUESE RED</td>\n",
       "      <td>J. Portugal Ramos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71079</td>\n",
       "      <td>France</td>\n",
       "      <td>A solid, chunky wine, with a structure that is...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.041695</td>\n",
       "      <td>Bordeaux</td>\n",
       "      <td>Lalande de Pomerol</td>\n",
       "      <td>BORDEAUX-STYLE RED BLEND</td>\n",
       "      <td>Château Tour Grand Colombier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32440</td>\n",
       "      <td>France</td>\n",
       "      <td>This is powerful and concentrated, with the hi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.085021</td>\n",
       "      <td>Bordeaux</td>\n",
       "      <td>Saint-Émilion</td>\n",
       "      <td>BORDEAUX-STYLE RED BLEND</td>\n",
       "      <td>Château Figeac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124405</td>\n",
       "      <td>US</td>\n",
       "      <td>Rich, ripe and oaky, this Petite Sirah charms ...</td>\n",
       "      <td>Thompson Vineyard</td>\n",
       "      <td>89.869797</td>\n",
       "      <td>California</td>\n",
       "      <td>Santa Barbara County</td>\n",
       "      <td>PETITE SIRAH</td>\n",
       "      <td>Jaffurs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33649</td>\n",
       "      <td>US</td>\n",
       "      <td>This wine is a unique in the state blend and f...</td>\n",
       "      <td>McKinley Springs Vineyard</td>\n",
       "      <td>89.017651</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Horse Heaven Hills</td>\n",
       "      <td>ROSé</td>\n",
       "      <td>Syncline</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         country                                        description  \\\n",
       "id                                                                    \n",
       "32027   Portugal  This is a fine rich balanced wine. It has ripe...   \n",
       "71079     France  A solid, chunky wine, with a structure that is...   \n",
       "32440     France  This is powerful and concentrated, with the hi...   \n",
       "124405        US  Rich, ripe and oaky, this Petite Sirah charms ...   \n",
       "33649         US  This wine is a unique in the state blend and f...   \n",
       "\n",
       "                      designation     points    province  \\\n",
       "id                                                         \n",
       "32027          Vila Santa Reserva  88.870874  Alentejano   \n",
       "71079                         NaN  88.041695    Bordeaux   \n",
       "32440                         NaN  94.085021    Bordeaux   \n",
       "124405          Thompson Vineyard  89.869797  California   \n",
       "33649   McKinley Springs Vineyard  89.017651  Washington   \n",
       "\n",
       "                    region_1                   variety  \\\n",
       "id                                                       \n",
       "32027                    NaN            PORTUGUESE RED   \n",
       "71079     Lalande de Pomerol  BORDEAUX-STYLE RED BLEND   \n",
       "32440          Saint-Émilion  BORDEAUX-STYLE RED BLEND   \n",
       "124405  Santa Barbara County              PETITE SIRAH   \n",
       "33649     Horse Heaven Hills                      ROSé   \n",
       "\n",
       "                              winery  \n",
       "id                                    \n",
       "32027              J. Portugal Ramos  \n",
       "71079   Château Tour Grand Colombier  \n",
       "32440                 Château Figeac  \n",
       "124405                       Jaffurs  \n",
       "33649                       Syncline  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Imputation\n",
    "for column in list(train.columns):\n",
    "    train[str(column)].fillna(train[str(column)].mode()[0], inplace=True)\n",
    "    test[str(column)].fillna(test[str(column)].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "train.columns = train.columns.astype(str)\n",
    "test.columns = test.columns.astype(str)\n",
    "vocab_size = 20000\n",
    "word_count = lambda sentence: len(word_tokenize(sentence))\n",
    "dic = {}\n",
    "DICT = {}\n",
    "for column in  train.drop(columns = ['points']).columns:\n",
    "    column_name = column\n",
    "    longest_sentence = max(train[str(column)], key=word_count)\n",
    "    length_long_sentence = len(word_tokenize(longest_sentence))\n",
    "    column_train = [one_hot(sent, vocab_size) for sent in train[str(column)]]\n",
    "    column_test = [one_hot(sent, vocab_size) for sent in test[str(column)]]\n",
    "    dic[str(column_name)] = pad_sequences(column_train, length_long_sentence, padding='post')\n",
    "    DICT[str(column_name)] = pad_sequences(column_test, length_long_sentence, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11307,     0,     0],\n",
       "       [13441,     0,     0],\n",
       "       [13441,     0,     0],\n",
       "       ...,\n",
       "       [ 8688,     0,     0],\n",
       "       [ 3895,     0,     0],\n",
       "       [ 3895,     0,     0]], dtype=int32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic['country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175000, 210)\n",
      "(83210, 210)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "TRAIN = np.concatenate((dic['country'], dic['description'], dic['designation'], dic['province'], dic['region_1'], dic['variety'], dic['winery'], train[['points']].to_numpy()), axis=1)\n",
    "TEST = np.concatenate((DICT['country'], DICT['description'], DICT['designation'], DICT['province'], DICT['region_1'], DICT['variety'], DICT['winery'], test[['points']].to_numpy()), axis=1)\n",
    "print(TRAIN.shape)\n",
    "print(TEST.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 210, 18)           360000    \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 3780)              0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 13)                49153     \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 14        \n",
      "=================================================================\n",
      "Total params: 409,167\n",
      "Trainable params: 409,167\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "# checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "embedding_dim = 18\n",
    "A_model = Sequential()\n",
    "A_model.add(layers.Embedding(input_dim=20000, output_dim=embedding_dim, input_length=TRAIN.shape[1]))\n",
    "A_model.add(layers.Flatten())\n",
    "A_model.add(layers.Dense(13, activation='relu'))\n",
    "# A_model.add(layers.Dense(8, activation='relu'))\n",
    "A_model.add(layers.Dense(1, activation='linear'))\n",
    "A_model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "A_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 157500 samples, validate on 17500 samples\n",
      "Epoch 1/30\n",
      "157500/157500 [==============================] - 80s 506us/step - loss: 786.8679 - accuracy: 0.0399 - val_loss: 1074.9370 - val_accuracy: 0.0495\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.04949, saving model to weights-improvement-01-0.05.hdf5\n",
      "Epoch 2/30\n",
      "157500/157500 [==============================] - 81s 515us/step - loss: 458.5516 - accuracy: 0.0544 - val_loss: 889.4360 - val_accuracy: 0.0538\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.04949 to 0.05377, saving model to weights-improvement-02-0.05.hdf5\n",
      "Epoch 3/30\n",
      "157500/157500 [==============================] - 100s 633us/step - loss: 300.4310 - accuracy: 0.0613 - val_loss: 806.5790 - val_accuracy: 0.0613\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.05377 to 0.06131, saving model to weights-improvement-03-0.06.hdf5\n",
      "Epoch 4/30\n",
      "157500/157500 [==============================] - 92s 587us/step - loss: 214.7861 - accuracy: 0.0661 - val_loss: 758.9742 - val_accuracy: 0.0589\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.06131\n",
      "Epoch 5/30\n",
      "157500/157500 [==============================] - 81s 516us/step - loss: 165.0891 - accuracy: 0.0712 - val_loss: 701.1318 - val_accuracy: 0.0625\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.06131 to 0.06251, saving model to weights-improvement-05-0.06.hdf5\n",
      "Epoch 6/30\n",
      "157500/157500 [==============================] - 83s 528us/step - loss: 129.9149 - accuracy: 0.0756 - val_loss: 662.3828 - val_accuracy: 0.0710\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.06251 to 0.07097, saving model to weights-improvement-06-0.07.hdf5\n",
      "Epoch 7/30\n",
      "157500/157500 [==============================] - 98s 620us/step - loss: 111.4216 - accuracy: 0.0799 - val_loss: 657.8191 - val_accuracy: 0.0702\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.07097\n",
      "Epoch 8/30\n",
      "157500/157500 [==============================] - 86s 548us/step - loss: 93.9882 - accuracy: 0.0841 - val_loss: 627.9869 - val_accuracy: 0.0551\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.07097\n",
      "Epoch 9/30\n",
      "157500/157500 [==============================] - 96s 607us/step - loss: 84.6016 - accuracy: 0.0897 - val_loss: 609.8891 - val_accuracy: 0.0721\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.07097 to 0.07211, saving model to weights-improvement-09-0.07.hdf5\n",
      "Epoch 10/30\n",
      "157500/157500 [==============================] - 84s 532us/step - loss: 75.3106 - accuracy: 0.0939 - val_loss: 584.4596 - val_accuracy: 0.0759\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.07211 to 0.07589, saving model to weights-improvement-10-0.08.hdf5\n",
      "Epoch 11/30\n",
      "157500/157500 [==============================] - 86s 548us/step - loss: 67.3806 - accuracy: 0.0978 - val_loss: 541.0385 - val_accuracy: 0.0805\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.07589 to 0.08046, saving model to weights-improvement-11-0.08.hdf5\n",
      "Epoch 12/30\n",
      "157500/157500 [==============================] - 82s 518us/step - loss: 60.8313 - accuracy: 0.1037 - val_loss: 539.1572 - val_accuracy: 0.0846\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.08046 to 0.08457, saving model to weights-improvement-12-0.08.hdf5\n",
      "Epoch 13/30\n",
      "157500/157500 [==============================] - 85s 538us/step - loss: 55.4604 - accuracy: 0.1063 - val_loss: 517.9673 - val_accuracy: 0.0848\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.08457 to 0.08480, saving model to weights-improvement-13-0.08.hdf5\n",
      "Epoch 14/30\n",
      "157500/157500 [==============================] - 88s 558us/step - loss: 48.9073 - accuracy: 0.1093 - val_loss: 505.7429 - val_accuracy: 0.0883\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.08480 to 0.08829, saving model to weights-improvement-14-0.09.hdf5\n",
      "Epoch 15/30\n",
      "157500/157500 [==============================] - 86s 547us/step - loss: 45.6709 - accuracy: 0.1135 - val_loss: 494.8468 - val_accuracy: 0.0867\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.08829\n",
      "Epoch 16/30\n",
      "157500/157500 [==============================] - 86s 547us/step - loss: 41.2067 - accuracy: 0.1180 - val_loss: 470.4207 - val_accuracy: 0.0873\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.08829\n",
      "Epoch 17/30\n",
      "157500/157500 [==============================] - 83s 527us/step - loss: 38.1109 - accuracy: 0.1220 - val_loss: 501.2106 - val_accuracy: 0.0909\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.08829 to 0.09091, saving model to weights-improvement-17-0.09.hdf5\n",
      "Epoch 18/30\n",
      "157500/157500 [==============================] - 86s 543us/step - loss: 37.4043 - accuracy: 0.1255 - val_loss: 463.8262 - val_accuracy: 0.0927\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.09091 to 0.09269, saving model to weights-improvement-18-0.09.hdf5\n",
      "Epoch 19/30\n",
      "157500/157500 [==============================] - 80s 510us/step - loss: 33.9891 - accuracy: 0.1288 - val_loss: 483.6777 - val_accuracy: 0.0926\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.09269\n",
      "Epoch 20/30\n",
      "157500/157500 [==============================] - 80s 505us/step - loss: 32.5670 - accuracy: 0.1307 - val_loss: 463.1016 - val_accuracy: 0.0994\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.09269 to 0.09937, saving model to weights-improvement-20-0.10.hdf5\n",
      "Epoch 21/30\n",
      "157500/157500 [==============================] - 80s 508us/step - loss: 31.4973 - accuracy: 0.1343 - val_loss: 495.0991 - val_accuracy: 0.0964\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.09937\n",
      "Epoch 22/30\n",
      "157500/157500 [==============================] - 79s 501us/step - loss: 30.9325 - accuracy: 0.1372 - val_loss: 465.2722 - val_accuracy: 0.0755\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.09937\n",
      "Epoch 23/30\n",
      "157500/157500 [==============================] - 60s 379us/step - loss: 28.4119 - accuracy: 0.1397 - val_loss: 484.7898 - val_accuracy: 0.0973\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.09937\n",
      "Epoch 24/30\n",
      "157500/157500 [==============================] - 74s 472us/step - loss: 28.5009 - accuracy: 0.1421 - val_loss: 477.5132 - val_accuracy: 0.0946\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.09937\n",
      "Epoch 25/30\n",
      "157500/157500 [==============================] - 80s 505us/step - loss: 26.1670 - accuracy: 0.1448 - val_loss: 480.9350 - val_accuracy: 0.0962\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.09937\n",
      "Epoch 26/30\n",
      "157500/157500 [==============================] - 80s 506us/step - loss: 25.4948 - accuracy: 0.1476 - val_loss: 484.2189 - val_accuracy: 0.1039\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.09937 to 0.10389, saving model to weights-improvement-26-0.10.hdf5\n",
      "Epoch 27/30\n",
      "157500/157500 [==============================] - 81s 513us/step - loss: 25.9121 - accuracy: 0.1507 - val_loss: 480.8992 - val_accuracy: 0.0998\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.10389\n",
      "Epoch 28/30\n",
      "157500/157500 [==============================] - 79s 503us/step - loss: 23.2395 - accuracy: 0.1524 - val_loss: 484.8537 - val_accuracy: 0.1051\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.10389 to 0.10509, saving model to weights-improvement-28-0.11.hdf5\n",
      "Epoch 29/30\n",
      "157500/157500 [==============================] - 80s 507us/step - loss: 23.6836 - accuracy: 0.1553 - val_loss: 483.8722 - val_accuracy: 0.1076\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.10509 to 0.10760, saving model to weights-improvement-29-0.11.hdf5\n",
      "Epoch 30/30\n",
      "157500/157500 [==============================] - 79s 504us/step - loss: 23.1170 - accuracy: 0.1554 - val_loss: 485.6234 - val_accuracy: 0.1027\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.10760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f42b37a2e10>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_model.fit(TRAIN, labels, epochs=30, batch_size = 16, validation_split=0.1, callbacks=callbacks_list, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please After Training Get the best model and best it below. \n",
    "\n",
    "A_model.load_weights(\"---------------------\")\n",
    "A_model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83210, 1)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = A_model.predict(TEST)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[126.06577 ],\n",
       "       [ 37.875286],\n",
       "       [ 52.801056],\n",
       "       ...,\n",
       "       [ 44.180225],\n",
       "       [ 20.896353],\n",
       "       [ 49.89761 ]], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[135.25145 ],\n",
       "       [ 39.39938 ],\n",
       "       [ 50.85417 ],\n",
       "       ...,\n",
       "       [ 26.403248],\n",
       "       [ 29.735802],\n",
       "       [ 58.787224]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  price\n",
       "0   0     50\n",
       "1   1     50\n",
       "2   2     50\n",
       "3   3     50\n",
       "4   4     50"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm_df = pd.read_csv('ammi-bootcamp-kaggle-competition/Sample_Submission.csv')\n",
    "subm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please type the 'submission' filename\n",
    "subm_df['price'] = predictions\n",
    "subm_df.to_csv('-----------------.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
